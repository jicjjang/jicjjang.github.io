{"componentChunkName":"component---src-templates-post-template-tsx","path":"/posts/langchain-ai-concept","result":{"data":{"site":{"siteMetadata":{"title":"June"}},"markdownRemark":{"id":"970d04df-867a-5437-877b-de1840e5248f","excerpt":"LangChain은 프레임워크 LLM (Large Language Model)으로 서비스를 만들 수 있게 도와줌\n\n LLM 우리가 아는 chatGPT도 LLM 중 하나 chatGPT처럼 대화형 AI 서비스에서 이용하는게 LLM인가? 그건 chatGPT를 이용해 OpenAI…","html":"<ul>\n<li>\n<p>LangChain은 프레임워크</p>\n<ul>\n<li>LLM (Large Language Model)으로 서비스를 만들 수 있게 도와줌\n<span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 346px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/287b201e47d72f2feff15ab3954716ec/8f77f/ai-model1.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 165%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAhCAYAAADZPosTAAAACXBIWXMAABYlAAAWJQFJUiTwAAAE10lEQVRIx5WWeVMiSRDF3VU55UYQBQGRw/tCRcfxvgAVR5TxmtU1Yr7/R8itXzbVMhsbG7t/ZFR1dVGdL/O9VwwlU9OSma1LulSXXLYgnduuNBp7sra2JcfH5zI/vyKRSFISiYn/FEMcOFnelJQ5sJAvydvbhzw9vUqv9yQfHz9lc3P3/x0Yj6clFk1K3EQslpZgMCpjYzEJheISCET0sGQy86+H2PecNaQL45MmpnQhFktJNDquBw3OGe08EnHmfJQxHE7ob50MzemhSEKCoZik0jkpFssyN7csS0vrUiiUJZ+flVKppvPp6ZLUaou6Riwvb0g2W9R6T0zkNIGhmDnVFwjJ8IhHijM1ub9/kuvrO7m8vJKzs6bc3X2Xx8cfZt7SaLdvzVpPWq2OvLy8ycZGQ05PL2VyMu8cmEhkZDyVNZHTtC0E4Aw2g3V+YEtBDEJm3amhgRzlILOBw1nka8Cj2Dwzjps6czDvbL2Ay7tisaL72aOQPb6A/Pb7sIE8J72HZ4V5c9OVi4srhQdk5ufnLV3nfbvdkff3n7K19cW8a8vXr8f6Mc0wkZyUuMkulZoyxS5JJjMt6XRWR74+M1OVqamC5HIzOtIQMiJDfkNDCO2yPRDaUBe/P6w1YQ4feYaPzAlqxRp8pYbsBaqtsUL2+oIG8ojkC1W5urrVLjMeHZ1rt4F5eHgm+/sn0mxem7VrI8sLeX5+k5WVuna8Vlv6zJCGwEVqAKfQb6WyoJugBXVibWFhVYM9cHB1dVOhl8vzhqtVhe3SJpWe1rRHRwPi84UUJqPHE9Rg7vOFFa7dw2hlass0RDP8htijHp9MZUuyu7svBwenCrde39Hs9vaONFMyY769vafPrdaNVKuLCp/muQeOhePi84dM+rOqDvsjgudm80Z2dvbNxw703cnJpdYTunAgH6YkLmQ0nJ5wIHu8Y+I1ASTgOVBDbreZ895Ct0xwlWIzDATDeijNoODAm52d06A5jPBxcXFN5xgGmdEUPJOGkpBbw+FRrxSKNekaFbSMCjACoN3ePhizfTEG0NQAPmuMKAjaUG+S+FuXMYeUdgsYlrjWB60BMNo5exx/TLpG6/IwYn6UNIqB9UiMriE/nhntnHeMBBJEetYwFPKnUvrmYOB9+9ZTtWAI3e53c8f80TeHtqqm231UX8QcoA9qovto39Ey1tTPDvHzVZsZRScT6kMmmUxO9xCsWWvjHftdcyAgJtSIKvyM1pA6EdZ07R7qbOtL2Odf/DBfrErHQOp0ugqZLiN8SoAaMAh8ELgQ/vX1T6UXjEBRarBkGDMFDZvTM5m8Xk5wEZ7BN2ixvr6lioCPBHtQBpzEE+FnpTLfN9gB2kTN3fxpBI46vH3leAcUxGhV4/dHXPr0/TCjt96IIXbOaHnfWDmaJSDywcGJKgHyYhoE0LGuer2hmsbSqJ9zLyecexlzKJXmVAUchhIwUwwCumCqjcZX1ySAvLd3qHRBJe6Bg+YQM4tAGTQHSgAk1phb6Lb7rLHvlwz514CeJ0xTKDr/HGgCHaQBNIgGMCcbApdGTXSXZ/5ZuH4YGIuoOZQri4YK7wrvwVynvd6zwu107lVBKALFYKx8DPg8o57t7S/KVYXMjaeRdK5SCGwveAgLv+wtyDv7r+Kf/mX8BSNUnl3e0Jw/AAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"ai-modal1\"\n        title=\"ai-modal1\"\n        src=\"/static/287b201e47d72f2feff15ab3954716ec/8f77f/ai-model1.png\"\n        srcset=\"/static/287b201e47d72f2feff15ab3954716ec/070ae/ai-model1.png 120w,\n/static/287b201e47d72f2feff15ab3954716ec/8ff5a/ai-model1.png 240w,\n/static/287b201e47d72f2feff15ab3954716ec/8f77f/ai-model1.png 346w\"\n        sizes=\"(max-width: 346px) 100vw, 346px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span>\n<span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 332px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/e1e269da005f02e5c119e1d40707a250/f8dc5/ai-model2.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 188.33333333333331%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAmCAYAAADEO7urAAAACXBIWXMAABYlAAAWJQFJUiTwAAAFPUlEQVRIx2WW6VYjOQyFM/QM0JC1sgNptrCHfScBEiB0EiBhb+CwnOkz7/8KGn8qVAT6h8u27HLpSlfXFUp4OekfiIiXzMuPH5MyM1OSqak5KRbnZGlpXfuJiRmZn1+W5eUNmZ0tyehoUVZWNqRQmJC1tW1nW5R0ekji8bSEojxCIYklsnJwcCytVkdOTppycXElnc6tHB835Ojop7TbN3J5eSe12qmsrm5Jo3HhDt2U8/MrfQcnPC8rIS+Zk3DUk3giI5VKTXZ3D9QzDl1f31EPdnYqbrytHprHeMV4bm5JD6YfHh6TUCo1JNncqKRSeRkYiEl/f0S+f49KX19Ye2vYaYODcYlEPN1Lzxx7JJL0PYy7xz+9/ZJwnk5NzevXFhfX1Mvt7YqUSqsav42NXefpfuAla5OTs+oZqPA6Gk1KKOag9nz7W6LxjMbs6upeTk9b8vz8r4vjtcaKOHU6N3J2dil7e4f60cPDYw0HMWYN2yfISechmcLtWCylIaAnc6zxdSACDRtzW7f9vB+CLmQ66QwJ5202OyKZzLBuGBkZD8a5XEHn+fwPtUGxoaFR3c86B2sMo/GU0gbIpP/m5kGhPT6+yt3dk45p9/dPOif7m5t7Ggrg3t4+OPgnerh6qJ45SAl3+tLSmiZgfHxa40PwadhIwNjYlL5Ig9R4Wyz6djzWA4lhOlNQt40iUIIeSoTDiYAuNGLX3VinMVbIZPmvnm8SdyW4tVWWarWulbG7u6/wGFNB2KENdGIOVZ6e3tROudLIgfKwr39AYZN6Nu7v1xzPyvoiNKHciFu5XFVeWv0SQz4yM7Og5Qh0hZzLjyk1gGSwGQPdh+/3ViUGn2oiHEYfhYxnA+GYqg3JKLoin55eCOqVSsAOJFSG4GPD062tPfUMZ4BLH6gN0Ksu/e32tVZLvd6S6+t7rRao1Gy2lT6UHFARkrOzjsaRw8m4emhZTjoPyTQN4kJYIzk9XzeSWxVZdRjBPS/j89BzLfnOdjZCARsDxeZ4YIdYmQb7XJ9Kj3RBdgJLRoHYarWdQJwpJESg2bxwFfGomYcBzKkqYJN5yO8l0pIZmvwQWK6CeRdsNhHohYUVpRF9o3HuKHSkCUHiTNJIErycde/lqGkXui61yX+igomqCWhvbzgQVmxGFVMd4Ce/CizUwCtElEvIPMUbqgi6YMNDSwrJsuY5lIHAEkPgoirQA2oQJ2L48vLb0ePVfWhdDwYmnv15YPazwALBsmoNG3SxbA4OJhQ6L5sY845ChtjdAgsVeJmGoBoX2cwc8tKQLuZ4SBWxP/DQBJZ7GeX49evZVcqdwqZigE4YgM11WqvV9e7Z3z9yatSQh4cXrSgOxttAYKEPNCAJ1DFjehSEuJVKK+oVKPAaL1mHSvDQkLyX3ohCRihNYE1tTGBNVeyywm6qwz7WNIa+wPaowEKJavVE4ZBxMox3aCSVwzrVhE5CLe4SayiU/tuYwNJzmRM7NiCcdiCXEyUJT+Eih0GdSqWqe/kId04A2QQWGCaq1rABkVCYuDL+uKf9Zve3L7CDvsBaoMkYX6QxLhTGFZLZ+VUxqnST+5026U+0QTChC4pjtIEyb2//6b0CvNfX3yoSX8vvi8D6AoqXUMDogQ1aYLdfku7fFjsoqJRugeWLxKNbYNlo96+9mE5//PdY2Vn7Q2C5U0xgEQcqg78v5vx+kF3+ZKkW1uv1ptIIFEEtR5wHCCy3XLl8qNKFZNFj88ebShsqg0NXVzdVxuxmtLCE/HgMB/ExmhgtuqujW1RtT/dvHfD/BwZqMWTCg/vNAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"ai-modal2\"\n        title=\"ai-modal2\"\n        src=\"/static/e1e269da005f02e5c119e1d40707a250/f8dc5/ai-model2.png\"\n        srcset=\"/static/e1e269da005f02e5c119e1d40707a250/070ae/ai-model2.png 120w,\n/static/e1e269da005f02e5c119e1d40707a250/8ff5a/ai-model2.png 240w,\n/static/e1e269da005f02e5c119e1d40707a250/f8dc5/ai-model2.png 332w\"\n        sizes=\"(max-width: 332px) 100vw, 332px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></li>\n</ul>\n</li>\n</ul>\n<h3 id=\"LLM\" style=\"position:relative;\">LLM<a href=\"#LLM\" aria-label=\"LLM permalink\" class=\"autolink-headers-- after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h3>\n<ul>\n<li>우리가 아는 chatGPT도 LLM 중 하나</li>\n<li>\n<p>chatGPT처럼 대화형 AI 서비스에서 이용하는게 LLM인가?</p>\n<ul>\n<li>그건 chatGPT를 이용해 OpenAI에서 범용적 사용을 위해 서비스를 만들어 놓은 것</li>\n<li>chatGPT의 LLM 모델만 사용할수도 있음</li>\n</ul>\n</li>\n<li>\n<p><a href=\"https://smith.langchain.com/hub\" target=\"_blank\" rel=\"noopener\">https://smith.langchain.com/hub</a></p>\n<ul>\n<li>LangChain hub 사이트에서 모델이 얼마나 있는지 확인할 수 있음</li>\n<li>해당 모델들은 알만한 회사들의 모델들</li>\n<li>보통 뼈대가 되는 모델들도 위에 있는 모델들이 유명한 모델이긴 해도 다른 모델들이 많음</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"PROMPT-Engineering\" style=\"position:relative;\">PROMPT Engineering<a href=\"#PROMPT-Engineering\" aria-label=\"PROMPT Engineering permalink\" class=\"autolink-headers-- after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h3>\n<ul>\n<li>말 그대로 어떻게 더 효과적으로 LLM에게 질문을 할지에 대한 내용</li>\n<li>\n<p>원하는 AI 모델링 결과를 얻기위해 입력하는 모든것</p>\n<ul>\n<li>사전에 학습시키는 데이터</li>\n<li>상황마다 다른 유저의 입력</li>\n<li>모델을 조정하는 외부 정보</li>\n<li>...</li>\n</ul>\n</li>\n<li>\n<p>chatGPT3.5는 2021년 이전 데이터들을 학습했다고 한다. 그래서 날짜와 상관있는데 데이터에 대한 질문을 하면 (ex - <code class=\"language-text\">2024년 남자 테니스 랭킹 1위는 누구야?</code>) 이상한 답변을 진짜인것 마냥 답해줌</p>\n<ul>\n<li>이를 <code class=\"language-text\">할루시네이션</code> 이라고 함</li>\n<li>정확히는 정보가 없더라도 엉뚱한 대답 or 거짓으로 말을 이어나가는 현상</li>\n<li>이런 현상을 줄여나갈 수 있도록 노력해야 함</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"Chain\" style=\"position:relative;\">Chain<a href=\"#Chain\" aria-label=\"Chain permalink\" class=\"autolink-headers-- after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h3>\n<ul>\n<li>\n<p>LLM 사슬을 형성하여 연속 LLM 호출이 가능하도록 해줌</p>\n<ul>\n<li>(A 질문 => A 답변 => B 질문 => A 답변과 섞어서 B에 대한 답변...)</li>\n</ul>\n</li>\n<li>아래 설명할 RAG단계에서 store 이후 결과가 chain으로 넘어감</li>\n</ul>\n<h3 id=\"ReAct\" style=\"position:relative;\">ReAct<a href=\"#ReAct\" aria-label=\"ReAct permalink\" class=\"autolink-headers-- after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h3>\n<ul>\n<li>Reason &#x26; Action. 추론과 행동</li>\n<li>ReAct는 LLM과 결합하여 사용하는 일반적인 패러다임</li>\n<li>따라서 LLM은 질문에 대해 결과를 추론하고 결과를 얻기위해 행동함</li>\n<li>LLM의 프롬프팅 및 결과를 처리하는 방법 중 하나 (반드시 필요하진 않다는 뜻)</li>\n<li>모델 뿐 아니라 실제 세상의 정보들을 예측하는 용도로도 사용됨</li>\n<li>\n<p>시스템은 행동에 대한 계획을 생성, 유지 및 조정하는 동시에 외부 환경(예: Wikipedia)과의 상호 작용을 통해 추론에 추가 정보를 통합</p>\n<ul>\n<li>이러한 외부환경을 Agent와 Tool을 통해 제공</li>\n</ul>\n</li>\n<li>\n<p>ReAct의 예와 질문 답변을 수행하는데 필요한 도구의 예시\n<span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 332px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/e1e269da005f02e5c119e1d40707a250/f8dc5/ai-model2.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 188.33333333333331%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAmCAYAAADEO7urAAAACXBIWXMAABYlAAAWJQFJUiTwAAAFPUlEQVRIx2WW6VYjOQyFM/QM0JC1sgNptrCHfScBEiB0EiBhb+CwnOkz7/8KGn8qVAT6h8u27HLpSlfXFUp4OekfiIiXzMuPH5MyM1OSqak5KRbnZGlpXfuJiRmZn1+W5eUNmZ0tyehoUVZWNqRQmJC1tW1nW5R0ekji8bSEojxCIYklsnJwcCytVkdOTppycXElnc6tHB835Ojop7TbN3J5eSe12qmsrm5Jo3HhDt2U8/MrfQcnPC8rIS+Zk3DUk3giI5VKTXZ3D9QzDl1f31EPdnYqbrytHprHeMV4bm5JD6YfHh6TUCo1JNncqKRSeRkYiEl/f0S+f49KX19Ye2vYaYODcYlEPN1Lzxx7JJL0PYy7xz+9/ZJwnk5NzevXFhfX1Mvt7YqUSqsav42NXefpfuAla5OTs+oZqPA6Gk1KKOag9nz7W6LxjMbs6upeTk9b8vz8r4vjtcaKOHU6N3J2dil7e4f60cPDYw0HMWYN2yfISechmcLtWCylIaAnc6zxdSACDRtzW7f9vB+CLmQ66QwJ5202OyKZzLBuGBkZD8a5XEHn+fwPtUGxoaFR3c86B2sMo/GU0gbIpP/m5kGhPT6+yt3dk45p9/dPOif7m5t7Ggrg3t4+OPgnerh6qJ45SAl3+tLSmiZgfHxa40PwadhIwNjYlL5Ig9R4Wyz6djzWA4lhOlNQt40iUIIeSoTDiYAuNGLX3VinMVbIZPmvnm8SdyW4tVWWarWulbG7u6/wGFNB2KENdGIOVZ6e3tROudLIgfKwr39AYZN6Nu7v1xzPyvoiNKHciFu5XFVeWv0SQz4yM7Og5Qh0hZzLjyk1gGSwGQPdh+/3ViUGn2oiHEYfhYxnA+GYqg3JKLoin55eCOqVSsAOJFSG4GPD062tPfUMZ4BLH6gN0Ksu/e32tVZLvd6S6+t7rRao1Gy2lT6UHFARkrOzjsaRw8m4emhZTjoPyTQN4kJYIzk9XzeSWxVZdRjBPS/j89BzLfnOdjZCARsDxeZ4YIdYmQb7XJ9Kj3RBdgJLRoHYarWdQJwpJESg2bxwFfGomYcBzKkqYJN5yO8l0pIZmvwQWK6CeRdsNhHohYUVpRF9o3HuKHSkCUHiTNJIErycde/lqGkXui61yX+igomqCWhvbzgQVmxGFVMd4Ce/CizUwCtElEvIPMUbqgi6YMNDSwrJsuY5lIHAEkPgoirQA2oQJ2L48vLb0ePVfWhdDwYmnv15YPazwALBsmoNG3SxbA4OJhQ6L5sY845ChtjdAgsVeJmGoBoX2cwc8tKQLuZ4SBWxP/DQBJZ7GeX49evZVcqdwqZigE4YgM11WqvV9e7Z3z9yatSQh4cXrSgOxttAYKEPNCAJ1DFjehSEuJVKK+oVKPAaL1mHSvDQkLyX3ohCRihNYE1tTGBNVeyywm6qwz7WNIa+wPaowEKJavVE4ZBxMox3aCSVwzrVhE5CLe4SayiU/tuYwNJzmRM7NiCcdiCXEyUJT+Eih0GdSqWqe/kId04A2QQWGCaq1rABkVCYuDL+uKf9Zve3L7CDvsBaoMkYX6QxLhTGFZLZ+VUxqnST+5026U+0QTChC4pjtIEyb2//6b0CvNfX3yoSX8vvi8D6AoqXUMDogQ1aYLdfku7fFjsoqJRugeWLxKNbYNlo96+9mE5//PdY2Vn7Q2C5U0xgEQcqg78v5vx+kF3+ZKkW1uv1ptIIFEEtR5wHCCy3XLl8qNKFZNFj88ebShsqg0NXVzdVxuxmtLCE/HgMB/ExmhgtuqujW1RtT/dvHfD/BwZqMWTCg/vNAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"ai-modal2\"\n        title=\"ai-modal2\"\n        src=\"/static/e1e269da005f02e5c119e1d40707a250/f8dc5/ai-model2.png\"\n        srcset=\"/static/e1e269da005f02e5c119e1d40707a250/070ae/ai-model2.png 120w,\n/static/e1e269da005f02e5c119e1d40707a250/8ff5a/ai-model2.png 240w,\n/static/e1e269da005f02e5c119e1d40707a250/f8dc5/ai-model2.png 332w\"\n        sizes=\"(max-width: 332px) 100vw, 332px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<ul>\n<li>Template을 통해 Thought, Act, Obs가 반복됨을 볼 수 있음</li>\n<li>이러한 Template 형태로 보아 ReAct겠구나~ 에상 가능</li>\n<li>Search (아마 Goolge Search로 예상) Tool이 실행되고 있음을 알 수 있음</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"LLM과-Agent\" style=\"position:relative;\">LLM과 Agent<a href=\"#LLM%EA%B3%BC-Agent\" aria-label=\"LLM과 Agent permalink\" class=\"autolink-headers-- after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h3>\n<ul>\n<li>LLM - 학습된 데이터를 <code class=\"language-text\">읽어서</code> 유저의 query 결과를 도출</li>\n<li>\n<p>Agent - 학습된 데이터와 유저가 추가한 데이터를 섞어서 query의 결과를 도출</p>\n<ul>\n<li>기본적인 template 만으로 수행할 수 없는 작업을 해줌</li>\n<li>데이터를 <code class=\"language-text\">읽고 쓸 수</code> 있음</li>\n<li>또한 이 결과를 바탕으로 제공된 <code class=\"language-text\">Tool</code> 목록에서 원하는 Tool을 골라 결과 도출에 사용함</li>\n<li>ex) 챗봇 - 고객의 정보와 유저가 필요한 정보(유저의 질문 query)를 조합해 결과를 도출</li>\n<li>ex) 웹검색을 해주는 툴, sql 쿼리를 작성해 정보를 제공해주는 툴 등등이 있음</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"Memory\" style=\"position:relative;\">Memory<a href=\"#Memory\" aria-label=\"Memory permalink\" class=\"autolink-headers-- after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h3>\n<ul>\n<li>\n<p>기본적으로 LLM 모델이 대화하는 내용들을 저장까지 하진 않음</p>\n<ul>\n<li>보통 chatGPT 모델을 쓰다보니 잊고있음. chatGPT는 자체적으로 Memorize 기능 지원</li>\n</ul>\n</li>\n<li>이는 채팅 이력을 기억하고 이를 기반으로 대화형 명령을 할 수 있도록 도와줌</li>\n</ul>\n<h3 id=\"RAG\" style=\"position:relative;\">RAG<a href=\"#RAG\" aria-label=\"RAG permalink\" class=\"autolink-headers-- after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h3>\n<ul>\n<li><a href=\"https://www.youtube.com/watch?v=NfQrRQmDrcc\" target=\"_blank\" rel=\"noopener\">https://www.youtube.com/watch?v=NfQrRQmDrcc</a></li>\n<li>검색 / 증강 / 생성</li>\n<li>검색 결과로 답변을 얻는 작업</li>\n<li>chatGPT 모델이 아닌 서비스가 RAG의 한 종류, 서비스라 보면 됨</li>\n<li>\n<p>전처리 (4개를 다 합하여 index 라고 부름)\n<span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 480px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/4d9e07902ca00079912e2a2b01627793/e8950/langchain-preprocess.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 41.66666666666667%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAAAsTAAALEwEAmpwYAAAB/UlEQVQozy1S70/TUBTtZxXZujG6rbWjc1LUbbh23drS/WBszg0iY0ED2ZSICotGhfjbEBLQGLNE4wc1REwMRonwicT47x3ve/jh5LZ59513zrlXEJU8RPkYgTM2TksZ+CJZDMVcSJqHoOpgMGwQTIiKzXtY9Uct3su+pbjH+/3RHIRwooJnmx/x5dsh0u51DEgGIokyzhkt6GYLicwsNU9gMGKh0FjG880PqM6uwq84CJCYsezcMaw21At1CFZpEZ93D7C3/wfdu69wIjhOLxY5UeHKbcSSTa7SL+fQW3uN3e+HWH/ZR2jE4yrNUgfl6RV41KulGhBSdhufvv7Gz4O/mL/5BKeGDSh6BflKF/bUDRjFRU7I7N9//BbrL/pYI6jnq9wiI3Rqt+BeXkY83YQgnZ3EnQdb2Hq3g6Q9j5OhS4gn69im/zf9HTzdeE+5ORhSXejZNrfHKnMhkmotNQ23toSUcw3R0SkIylgNWnoGo5RZLNmgy3n4ZBurD7fxY/8IVxceUa4mWZxAqbmCauseJmd6PGcfWWaEe7+OsNTbgKh6EGS9hnFvgec1QoeikkNIKyBb7qA+1+ODYpNkU8wUOzDLXY4wEXKFJIbFc5HcyXoVQoCag2SJrQ2zNTCcoQFYhDzPk5GxlWEI0jlbG1Z9/9eG3WEbwFeKpv4PXjgRqX2euS0AAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"langchain-preprocess.png\"\n        title=\"langchain-preprocess.png\"\n        src=\"/static/4d9e07902ca00079912e2a2b01627793/e85cb/langchain-preprocess.png\"\n        srcset=\"/static/4d9e07902ca00079912e2a2b01627793/070ae/langchain-preprocess.png 120w,\n/static/4d9e07902ca00079912e2a2b01627793/8ff5a/langchain-preprocess.png 240w,\n/static/4d9e07902ca00079912e2a2b01627793/e85cb/langchain-preprocess.png 480w,\n/static/4d9e07902ca00079912e2a2b01627793/37523/langchain-preprocess.png 720w,\n/static/4d9e07902ca00079912e2a2b01627793/d9199/langchain-preprocess.png 960w,\n/static/4d9e07902ca00079912e2a2b01627793/e8950/langchain-preprocess.png 2000w\"\n        sizes=\"(max-width: 480px) 100vw, 480px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<ul>\n<li>\n<p>아래 4개의 프로세스가 LLM을 통한 서비스를 만들 때 기본적으로 사전에 이루어져야 하는 작업들</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\"></code></pre></div>\n</li>\n<li>\n<p>LOAD</p>\n<ul>\n<li>파일들을 로드함</li>\n<li>여기서 파일은 유저의 입력 텍스트, text파일, json 파일, pdf 파일등등…</li>\n</ul>\n</li>\n<li>\n<p>SPLIT</p>\n<ul>\n<li>한번에 읽어들일 수 있는 토큰 수가 있기 때문에 파일을 모두 쪼개야 함. chunk파일로 분할</li>\n</ul>\n</li>\n<li>\n<p>EMBED</p>\n<ul>\n<li>이 파일들을 AI가 읽을 수 있도록 값으로 변환해주는 작업. 이 과정에 LLM 모델이 사용됨.</li>\n</ul>\n</li>\n<li>\n<p>STORE</p>\n<ul>\n<li>\n<p>vector db에 저장</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\"></code></pre></div>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>서비스\n<span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 480px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/d32402b9116194c18df7ed254ea3fb37/79166/langchain-service.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 44.99999999999999%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAABYlAAAWJQFJUiTwAAAB2UlEQVQoz42SS2sTYRSGZ2Frks5MpubWSUir0Aaby1wSY1Nsq3iZVqOpF1CxceGiaheCoC0qFReC9VIK0o34A5QKhS79EQr+Cv0Zj98lUboQXLzM+b5zznveeb9jmNkQMxtg5erYI419SLrHGM4LFJoir+v69f+C0SdLuo1eU6jIUsXjOHlNZI/UxXnqv0gV4V+yAFuQOzmf/PiMUNfAzGgCWZMWpEPiLAdIKBLZJ3oURJ0xlPGVQjU14+EejfCurHP++kPO3XpGMLekcvGURyLtK5KDw1UGkmUtIl3DTFU0RGyo3xttKZ8SaY9x/wIvt3e4ufqB59u7BJ1VYs4kJX+eUwtdBp0K1Wab5uw1MaSGNXYSa2JBwSzOYpTCi5zuLFObvoqV9RkLLvNo8wv1qUtE97ZYvLOOceAIj59u8O37DwaFurdbH9nd+0r8UJV49zOFd79w3/wk1t3RCh3xktIjUyh0y20WX+xx+8EGK68+cebGGgP2JBNexFy0pBSW/Ai/1SEmCK1CC3t0Bqt4ArMwrR9F+ii/0qPDlXlW1jZpL7/m7pP3lM/ex1L5EO13SEL4KT3t+658lBCxIS+tbPhnFeSq6Ds5IFB7qB8t6NUFinTfCuV6EPFvOxYQy2/kxwcAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"langchain-service.png\"\n        title=\"langchain-service.png\"\n        src=\"/static/d32402b9116194c18df7ed254ea3fb37/e85cb/langchain-service.png\"\n        srcset=\"/static/d32402b9116194c18df7ed254ea3fb37/070ae/langchain-service.png 120w,\n/static/d32402b9116194c18df7ed254ea3fb37/8ff5a/langchain-service.png 240w,\n/static/d32402b9116194c18df7ed254ea3fb37/e85cb/langchain-service.png 480w,\n/static/d32402b9116194c18df7ed254ea3fb37/37523/langchain-service.png 720w,\n/static/d32402b9116194c18df7ed254ea3fb37/d9199/langchain-service.png 960w,\n/static/d32402b9116194c18df7ed254ea3fb37/79166/langchain-service.png 2012w\"\n        sizes=\"(max-width: 480px) 100vw, 480px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\"></code></pre></div>\n</li>\n<li>\n<p>Question</p>\n<ul>\n<li>유저가 질문을 함</li>\n</ul>\n</li>\n<li>\n<p>RETRIEVE</p>\n<ul>\n<li>embed에서 질문을 바탕으로 필요한 내용을 발췌</li>\n</ul>\n</li>\n<li>\n<p>PROMPT</p>\n<ul>\n<li>발췌된 내용과 PROMPT에 정의된 내용을 바탕으로 LLM에 질의할 내용을 만듬</li>\n</ul>\n</li>\n<li>\n<p>LLM</p>\n<ul>\n<li>\n<p>만들어진 질의 내용을 가지고 LLM조회를 하여 답변을 해줌</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\"></code></pre></div>\n</li>\n</ul>\n</li>\n<li>\n<p>전처리 단계 조합</p>\n<ul>\n<li>\n<p>LOAD(150여 가지) -> SPLIT(10여 가지) -> EMBED(60여 가지) -> STORE(80여 가지) -> 360,000,000 경우의 수 조합이 가능함</p>\n<ul>\n<li>문서를 LOAD하는 전략이 150여 가지 (text, json, pdf 등등…)</li>\n<li>text SPLIT하는 전략이 10여가지</li>\n<li>문서를 EMBED하는 전략(모델)이 60여가지 (기본 60여 가지지만, <a href=\"https://huggingface.co/\" target=\"_blank\" rel=\"noopener\">https://huggingface.co/</a> 를 보면 이 전략이 엄청나게 많음…)</li>\n<li>EMBED된 문서를 Vector Store에 저장할 때의 Vector DB의 종류가 80여 가지</li>\n<li>Vector DB를 조회하기 위한 RETRIEVE 단계의 Vector DB 검색기 종류가 50여 가지</li>\n</ul>\n</li>\n<li>위에 기본 가지수는 랭체인 사용시 기본적으로 사용 가능한 개수들</li>\n<li>이렇게 많은 경우의 수가 있다…? => 결론은 다 테스트 해볼 순 없다!</li>\n<li>상황에 맞는 적절한 조합을 찾는게 중요하다.</li>\n</ul>\n</li>\n<li>\n<p>LOAD (PDF 기준)</p>\n<ul>\n<li>\n<p>선택시 고려 사항</p>\n<ul>\n<li>\n<p>텍스트를 원형 그대로 잘 가져오는지</p>\n<ul>\n<li>한글 인코딩</li>\n<li>특수문자, 수식</li>\n</ul>\n</li>\n<li>\n<p>메타데이터 종류</p>\n<ul>\n<li>본문 뿐만 아니라 페이지 번호, 차트, 좌표, 속성값 등등 모두 잘 가져오는지</li>\n<li>부가 메타데이터 속성들</li>\n</ul>\n</li>\n<li>문서를 읽는 속도</li>\n</ul>\n</li>\n<li>\n<p>종류</p>\n<ul>\n<li>fitz</li>\n<li>PyPDFLoader</li>\n<li>UnstructuredPDFLoader</li>\n<li>PDFPlumnber</li>\n<li>…</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>SPLIT (Text Splitter)</p>\n<ul>\n<li>문서를 특정 기준으로 분할(chunk)할 때 활용</li>\n<li>\n<p>종류</p>\n<ul>\n<li>CharacterTextSplitter</li>\n<li>RecursiveCharacterTextSplitter</li>\n<li>TokenTextSplitter</li>\n<li>HuggingFace</li>\n<li>SemanticChunker (experimental)</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>EMBED</p>\n<ul>\n<li>EMBED 이후 Vector Store에 저장해야 하는데, 저장 후 Semantic Search (의미 검색)과 같은 작업을 수행할 때 유용하게 사용할 수 있음.</li>\n<li>이 기능을 잘 활용하기 위해 잘 맞는 모델을 선택하는게 중요.</li>\n<li>또한 한국어도 가능하게 해야 하므로!! (optional)</li>\n<li>\n<p>랭체인의 EMBED 클래스는 두가지 메서드 존재</p>\n<ul>\n<li>문서를 import해서 DB에 넣을 때의 embed</li>\n<li>유저가 질문을 query 할때의 embed</li>\n<li>결국 위 2가지 embed된 내용의 유사성을 조사하는 것</li>\n</ul>\n</li>\n<li>가끔 위 두가지 메서드의 모델이 다른 경우가 있음. 그럼 유사성을 조사할 때 유사도가 떨어질 수 있으니 주의.</li>\n<li>\n<p>종류</p>\n<ul>\n<li>\n<p>OpenAIEmbedding</p>\n<ul>\n<li>보통은 이걸 사용. 무난. 사용성 좋음. 한글처리 좋음.</li>\n<li>다른 embedding 모델과 다르게 로컬에 저장해서 gpu를 쓰지 않음. (Api 형식)</li>\n<li>과금 압박이 생길 수 있음</li>\n</ul>\n</li>\n<li>\n<p>CacheBackedEmbeddings</p>\n<ul>\n<li>임베딩을 저장하거나 캐시해서 다시 계산할 필요가 없도록 해줌 (key-value)</li>\n<li>텍스트는 해시되서 캐시키로 사용</li>\n<li>캐시된 embedding 벡터 가져오는건 거의 0초에 수렴. 매우 빠름</li>\n<li>여러 모델을 사용하는 경우, namespace를 설정해서 캐시 가능</li>\n<li>ex1) openAiEmbedding으로 동일 문서를 10명이 조회한 경우 or 1명이 10번 조회한 경우 => 10번의 비용 발생</li>\n<li>ex2) openAiEmbedding + CacheBackedEmbeddings으로 같은 문서를 10, 100번 조회 => 캐시를 위한 1번의 비용만 발생</li>\n</ul>\n</li>\n<li>hugging face에서 벤치마크 점수만 믿으면 안됨. 우리는 한글도 처리해야 하니까…!</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>Vector Store</p>\n<ul>\n<li>확장성 있게 -> 클라우드 / 여러 사람이 자주, 빈번하게 조회 -> 로컬</li>\n<li>모델에 따라 고유 특성이 있고, 방대한 데이터 입/출에 대한 관리가 필요</li>\n<li>\n<p>인기 있는 Vector DB</p>\n<ul>\n<li>\n<p>클라우드</p>\n<ul>\n<li>PineCone</li>\n<li>Weaviate</li>\n<li>ElasticSearch</li>\n</ul>\n</li>\n<li>\n<p>로컬</p>\n<ul>\n<li>Chroma</li>\n<li>FAISS (meta) => 캐글 1등 팀이 썼었음</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>","frontmatter":{"title":"LangChain AI에 대한 개념","date":"June 09, 2024","tags":["langchain","ai","framework"]}}},"pageContext":{"slug":"/posts/langchain-ai-concept","previous":{"fields":{"slug":"/posts/flutter-tutorial"},"frontmatter":{"title":"Flutter로 앱개발 시작하기"}},"next":{"fields":{"slug":"/posts/hide-qr-code"},"frontmatter":{"title":"이미지에 QR Code 숨겨넣기"}}}},"staticQueryHashes":["1576648375","1963346411"]}